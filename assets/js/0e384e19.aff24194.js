"use strict";(self.webpackChunkxleap_docs=self.webpackChunkxleap_docs||[]).push([[976],{1512:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>a,toc:()=>c});var s=n(4848),r=n(8453);const o={sidebar_position:1},i="xLeap Intro",a={id:"intro",title:"xLeap Intro",description:"Let's discover xLeap in less than 5 minutes.",source:"@site/docs/intro.md",sourceDirName:".",slug:"/intro",permalink:"/docs/intro",draft:!1,unlisted:!1,editUrl:"https://github.com/xleap-ai/xleap/tree/master/docs/docs/intro.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",next:{title:"Getting started",permalink:"/docs/category/getting-started"}},l={},c=[{value:"Getting Started with xLeap",id:"getting-started-with-xleap",level:2},{value:"How long it takes to setup",id:"how-long-it-takes-to-setup",level:3}];function d(e){const t={a:"a",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.h1,{id:"xleap-intro",children:"xLeap Intro"}),"\n",(0,s.jsxs)(t.p,{children:["Let's discover ",(0,s.jsx)(t.strong,{children:"xLeap in less than 5 minutes"}),"."]}),"\n",(0,s.jsx)(t.h2,{id:"getting-started-with-xleap",children:"Getting Started with xLeap"}),"\n",(0,s.jsx)(t.p,{children:"LLMs have taken the world by storm. But they are still quite far away from adding value to end-user products. One of\nthe core challenges in using LLMs today is understanding when LLM fails to deliver its promise - loosely called as\nhallucination. To mitigate hallucinations, you need to evaluate your LLM. However, LLM evaluation isn\u2019t like evaluation\nor analytics in the API-first world. There is no one true answer and you can\u2019t measure performance quantifiably. Well\nyou can, but the metrics that are used are either non-interpretable by non-AI experts and/or have no correlation to the\nactual performance of the model."}),"\n",(0,s.jsx)(t.p,{children:"Imagine a scenario where a customer service chatbot, powered by an LLM, is interacting with a customer. The customer\nsays, \"I'm upset because my order hasn't arrived yet.\" A contextually aware response would acknowledge the customer's\nconcern and provide information about the order status. However, a less sophisticated LLM might generate a generic or\nirrelevant response, such as \"I'm sorry to hear that. Do you like our products?\""}),"\n",(0,s.jsx)(t.p,{children:"In this scenario, traditional evaluation metrics might rate both responses as acceptable since they syntactically fit\nthe conversational flow. However, the first response is more appropriate and helpful from a customer service\nperspective."}),"\n",(0,s.jsx)(t.p,{children:"The future lies in developing new kinds of evaluation tools for LLMs. These tools should be:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Understandable: Clear and simple enough for everyone, not just experts."}),"\n",(0,s.jsx)(t.li,{children:"Task-specific: Knowing which metrics for what type of tasks should be tracked."}),"\n",(0,s.jsx)(t.li,{children:"Reliable: Providing a true reflection of how well the model works in different situations."}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["PS: This is what our mission is at ",(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://xleaplabs.com",children:"xLeap ai"})}),". We\u2019re building a collaborative suite for\nsoftware devs and product managers of the world to ensure that they can accurately measure the LLMs performance and\ntake LLM to their end-users."]}),"\n",(0,s.jsx)(t.h3,{id:"how-long-it-takes-to-setup",children:"How long it takes to setup"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"xLeap is designed for quick setup, with the entire process taking less than 5 minutes."}),"\n",(0,s.jsx)(t.li,{children:"SDKs are available for popular programming languages, including Python, JavaScript, and TypeScript."}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>a});var s=n(6540);const r={},o=s.createContext(r);function i(e){const t=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),s.createElement(o.Provider,{value:t},e.children)}}}]);